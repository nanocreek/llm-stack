# LiteLLM Configuration File
# This is a minimal configuration that allows LiteLLM to start
# API keys should be set via environment variables

model_list:
  # OpenAI models - requires OPENAI_API_KEY environment variable
  - model_name: gpt-4
    litellm_params:
      model: gpt-4
      api_key: os.environ/OPENAI_API_KEY
  
  - model_name: gpt-4-turbo
    litellm_params:
      model: gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
  
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
  
  # Anthropic models - requires ANTHROPIC_API_KEY environment variable
  - model_name: claude-3-opus
    litellm_params:
      model: claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
  
  - model_name: claude-3-sonnet
    litellm_params:
      model: claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
  
  - model_name: claude-3-haiku
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY

# General settings
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Database settings for caching and logging (optional)
  # Uncomment and configure when PostgreSQL is available
  # database_url: os.environ/DATABASE_URL
  
  # Redis settings for distributed caching and rate limiting (optional)
  # Uncomment and configure when Redis is available
  # redis_host: os.environ/REDIS_HOST
  # redis_port: os.environ/REDIS_PORT
  # redis_password: os.environ/REDIS_PASSWORD

litellm_settings:
  success_callback: []
  failure_callback: []
  # Enable detailed logging
  set_verbose: false
